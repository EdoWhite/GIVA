{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "import torch\n",
    "import gradio as gr\n",
    "import librosa\n",
    "import openai\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What kind of probabilistic distribution is most suited for modeling the number of cars that arrive to a toll station in one hour? Answer only with the name of the distribution.\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisson distribution.\n"
     ]
    }
   ],
   "source": [
    "generated_text = completion.choices[0].message[\"content\"]\n",
    "print(generated_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-Siri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and processor for ASR\n",
    "checkpoint_asr = \"openai/whisper-base\"\n",
    "processor_asr = WhisperProcessor.from_pretrained(checkpoint_asr)\n",
    "model_asr = WhisperForConditionalGeneration.from_pretrained(checkpoint_asr)\n",
    "\n",
    "# load model and processor for TTS\n",
    "checkpoint_tts = \"microsoft/speecht5_tts\"\n",
    "vocoder_tts = \"microsoft/speecht5_hifigan\"\n",
    "processor_tts = SpeechT5Processor.from_pretrained(checkpoint_tts)\n",
    "model_tts = SpeechT5ForTextToSpeech.from_pretrained(checkpoint_tts)\n",
    "vocoder_tts = SpeechT5HifiGan.from_pretrained(vocoder_tts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(sampling_rate, waveform):\n",
    "    # convert from int16 to floating point\n",
    "    waveform = waveform / 32678.0\n",
    "\n",
    "    # convert to mono if stereo\n",
    "    if len(waveform.shape) > 1:\n",
    "        waveform = librosa.to_mono(waveform.T)\n",
    "\n",
    "    # resample to 16 kHz if necessary\n",
    "    if sampling_rate != 16000:\n",
    "        waveform = librosa.resample(waveform, orig_sr=sampling_rate, target_sr=16000)\n",
    "\n",
    "    # limit to 30 seconds\n",
    "    #waveform = waveform[:16000*30]\n",
    "\n",
    "    # make array\n",
    "    #waveform = torch.tensor(waveform)\n",
    "    waveform = np.array(waveform)\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript(audio):\n",
    "    # audio = tuple (sample_rate, frames) or (sample_rate, (frames, channels))\n",
    "    if audio is not None:\n",
    "        sampling_rate, waveform = audio\n",
    "    else:\n",
    "        return \"(please provide audio)\"\n",
    "\n",
    "    waveform = process_audio(sampling_rate, waveform)\n",
    "    \n",
    "    input = processor_asr(audio=waveform, sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "    predicted_ids = model_asr.generate(input)\n",
    "    transcription = processor_asr.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    return transcription[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToSpeech(text):\n",
    "    if len(text.strip()) == 0:\n",
    "        return (16000, np.zeros(0).astype(np.int16))\n",
    "\n",
    "    speaker_embedding = np.load(\"./speaker_embeddings/cmu_us_clb_arctic-wav-arctic_a0144.npy\")\n",
    "    speaker_embedding = torch.tensor(speaker_embedding).unsqueeze(0)\n",
    "\n",
    "    inputs = processor_tts(text=text, return_tensors=\"pt\")\n",
    "    speech = model_tts.generate_speech(inputs[\"input_ids\"], speaker_embedding, vocoder=vocoder_tts)\n",
    "    speech = (speech.numpy() * 32767).astype(np.int16)\n",
    "    return (16000, speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(openAI_key, audio):\n",
    "    openai.key = openAI_key\n",
    "    # Automatic Speech Recognition\n",
    "    prompt = transcript(audio)\n",
    "    # GPT gives an answer\n",
    "    completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    generated_text = completion.choices[0].message[\"content\"]\n",
    "    # Text to Speech\n",
    "    answer = textToSpeech(generated_text)\n",
    "    return prompt, generated_text, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edoardobianchi/DATA_SCIENZE/lib/python3.8/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "description = \"\"\"\n",
    "Your GPT-based vocal assistant. Speech recognition is performed with the <b>openai/whisper-base model</b>, while Text-to-Speech with <b>microsoft/speecht5_tts</b>.\n",
    "<br>\n",
    "<br>\n",
    "References:<br>\n",
    "<a href=\"https://huggingface.co/openai/whisper-base\">OpenAI Whisper-base</a><br>\n",
    "<a href=\"https://huggingface.co/microsoft/speecht5_tts\">Microsoft SpeechT5_tts</a><br>\n",
    "<a href=\"https://huggingface.co/blog/speecht5\">Matthijs, Huggingface - Speech Synthesis, Recognition, and More With SpeechT5</a><br>\n",
    "<a href=\"https://huggingface.co/docs/transformers/tasks/asr\">Huggingface - ASR with Transformers</a>.<br>\n",
    "<a href=\"https://platform.openai.com\">OpenAI API Reference</a><br>\n",
    "\"\"\"\n",
    "\n",
    "gr.Interface(\n",
    "    fn=chat,\n",
    "    inputs=[\n",
    "        gr.Text(label=\"OpenAI API Key\"),\n",
    "        gr.Audio(label=\"Record\", source=\"microphone\", type=\"numpy\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Text(label=\"Transcription\"),\n",
    "        gr.Text(label=\"GPT Answer\"),\n",
    "        gr.Audio(label=\"Speech Answer\", type=\"numpy\")\n",
    "    ],\n",
    "    title=\"GIVA - GPT-based Interactive Vocal Agent\",\n",
    "    description=description\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
